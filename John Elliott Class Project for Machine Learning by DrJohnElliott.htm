<!DOCTYPE html>
<html lang="en-us"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <meta charset="UTF-8">
    <title>John Elliott Class Project for Machine Learning by DrJohnElliott</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="John%20Elliott%20Class%20Project%20for%20Machine%20Learning%20by%20DrJohnElliott_files/normalize.css" media="screen">
    <link href="John%20Elliott%20Class%20Project%20for%20Machine%20Learning%20by%20DrJohnElliott_files/css.css" rel="stylesheet" type="text/css">
    <link rel="stylesheet" type="text/css" href="John%20Elliott%20Class%20Project%20for%20Machine%20Learning%20by%20DrJohnElliott_files/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="John%20Elliott%20Class%20Project%20for%20Machine%20Learning%20by%20DrJohnElliott_files/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">John Elliott Class Project for Machine Learning</h1>
      <h2 class="project-tagline">Coursera Data Science </h2>
      <a href="https://github.com/DrJohnElliott/MachineLearning" class="btn">View on GitHub</a>
      <a href="https://github.com/DrJohnElliott/MachineLearning/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/DrJohnElliott/MachineLearning/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h1>
<a id="machine-learning-week-4-class-project" class="anchor" href="#machine-learning-week-4-class-project" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Machine Learning Week 4 Class Project</h1>

<h2>
<a id="john-elliott" class="anchor" href="#john-elliott" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>John Elliott</h2>

<h3>
<a id="september-3-2016" class="anchor" href="#september-3-2016" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>September 3, 2016</h3>

<h2>
<a id="background-of-the-project" class="anchor" href="#background-of-the-project" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><strong>Background of the project:</strong>
</h2>

<p>This work is created for the final class project in the Practical 
Machine Learning Course, as part of the Coursera Data Science Track. To 
demonstrate machine learning techniques learned during the course data 
from <a href="http://groupware.les.inf.puc-rio.br/har">http://groupware.les.inf.puc-rio.br/har</a>
 is used to construct a model that can discern between the outcome 
variable “classe”. The data is from fitbit type devices worn by 
weightlifters performing exercises where they purposely performed the 
exercise with a particular type of fault which makes up the classe 
variable. The data experiment was published in the following paper:</p>

<p>Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. 
Qualitative Activity Recognition of Weight Lifting Exercises. 
Proceedings of 4th International Conference in Cooperation with SIGCHI 
(Augmented Human ’13) . Stuttgart, Germany: ACM SIGCHI, 2013. and you 
can read more about it here: <a href="http://groupware.les.inf.puc-rio.br/har#weight_lifting_exercises">http://groupware.les.inf.puc-rio.br/har#weight_lifting_exercises</a></p>

<h2>
<a id="executive-summary-of-the-results" class="anchor" href="#executive-summary-of-the-results" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><strong>Executive summary of the results:</strong>
</h2>

<p>To predict the outcome of the testing data, 3 models were developed. 
The first model, "Model 1" was a Classification Tree that used all 
predictor variables. It was not able to predict one of the classe type, <strong>"D"</strong>.
 Therefore another Classification Tree model was created, "Model 2" by 
sub-setting predictor variables by selecting them from feature plots 
where separation could be visually seen. Model 2 was able to predict all
 classe types but had slightly lower accuracy compared to Model 1. The 
performance of the two classification trees was disappointing, both with
 accuracy below 60%. A third model was created "Model 3" using a Random 
Forest method. This model yielded excellent performance with the data, 
with an accuracy of 99% and an estimated out of sample error of  
0.0008932247, was able to predict all outcomes of the test data 
accurately. Predictions from Model 3: B  A  B  A  A  E  D  B  A   A   B 
  C   B   A   E   E   A   B   B   B</p>

<h2>
<a id="code" class="anchor" href="#code" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><strong>Code:</strong>
</h2>

<h4>
<a id="git-hub-repository" class="anchor" href="#git-hub-repository" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>GIT HUB Repository</h4>

<p><a href="https://github.com/DrJohnElliott/MachineLearning/blob/master/Class_Project_week_4.Rmd">https://github.com/DrJohnElliott/MachineLearning/blob/master/Class_Project_week_4.Rmd</a></p>

<h3>
<a id="data-download" class="anchor" href="#data-download" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><strong>Data Download:</strong>
</h3>

<p>Data is downloaded from the defined URLs. The code makes a check to 
see if the required data file is present in the working directory. If it
 is not found then the file is downloaded and placed into the working 
directory.</p>

<pre><code>`URL &lt;- c("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",`
`"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")`
`required_files &lt;- c("pml-training.csv", "pml-testing.csv")`

    `for(i in 1:length(URL)){`
            `if(!all(lapply(required_files[i],file.exists)==TRUE)){ `
                    `print("Required Data Files Not Found!")`
                    `print("Please wait while the files are downloaded")`
                    `download.file(URL[i], destfile = required_files[i], mode="wb")`
            `}`
    `}`
</code></pre>

<h2>
<a id="load-data-into-environment-reading-in-data" class="anchor" href="#load-data-into-environment-reading-in-data" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Load Data Into Environment (Reading In Data)</h2>

<p>A check for the required data is made and if not found it is read 
into the environment. Also “cache = TRUE” is set for the data chunk to 
provide data caching.</p>

<pre><code>    `if(!exists("trainingData")){ `
            `print("Please Wait while dataset is loaded")`
            `trainingData &lt;- read.csv("pml-training.csv", header = TRUE, sep = "," ,`
                            `dec = ".",na.strings = c("", NA) )`
    `}`

    `if(!exists("testingData")){ `
            `print("Please Wait while dataset is loaded")`
            `testingData &lt;-  read.csv("pml-testing.csv", header = TRUE, sep = "," ,`
                            `dec = ".", na.strings = c("", NA) )`
    `}`
</code></pre>

<h2>
<a id="inspection-of-the-data-set" class="anchor" href="#inspection-of-the-data-set" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><strong>Inspection of the data set</strong>
</h2>

<p>First we take a quick look at the data set to see what we have.</p>

<pre><code>    `head(trainingData[ 3,1:5])`
    `str(trainingData[3, 1:5])`
</code></pre>

<hr>

<blockquote>
<p>X user_name raw_timestamp_part_1 raw_timestamp_part_2   cvtd_timestamp
3 3  carlitos           1323084231               820366 05/12/2011 11:23</p>
</blockquote>

<hr>

<blockquote>
<p>'data.frame':   1 obs. of  5 variables:
 $ X                   : int 3
 $ user_name           : Factor w/ 6 levels "adelmo","carlitos",..: 2
 $ raw_timestamp_part_1: int 1323084231
 $ raw_timestamp_part_2: int 820366
 $ cvtd_timestamp      : Factor w/ 20 levels "02/12/2011 13:32",..: 9</p>
</blockquote>

<hr>

<p>We check for incomplete data columns with Na’s in the two data sets, 
remove incomplete variables from the population and omit first 7 columns
 of descriptor variables.</p>

<pre><code>`testingData     &lt;- testingData[, colSums(is.na(testingData)) == 0] `
`trainingData    &lt;- trainingData[, colSums(is.na(trainingData)) == 0] `
`checknames      &lt;- is.na(match(colnames(trainingData), colnames(testingData)))`
`trainingData    &lt;- trainingData[,7:60]`
`testingData     &lt;- testingData[,7:60]`
</code></pre>

<p>We create a validation subset from the training data</p>

<pre><code>    `set.seed(1972) `
`inTrain         &lt;- createDataPartition(trainingData$classe, p = 0.7, list = FALSE)`
`trainingData    &lt;- trainingData[inTrain, ]`
`validate        &lt;- trainingData[-inTrain, ]`
</code></pre>

<h2>
<a id="exploratory-plots" class="anchor" href="#exploratory-plots" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><strong>Exploratory plots</strong>
</h2>

<p>Feature plots of the data are created to look for a subset of 
predictor variables. An example plot of 4 variables is shown, the 
process was repeated to find predictors that may improve the modeling 
accuracy. The list of predictors was placed in a variable named 
training_set.</p>

<pre><code>   `featurePlot(x = trainingData[, 10:13], `
        `y = trainingData$classe,`
        `plot = "ellipse",`
        `## Add a key at the top`
        `auto.key = list(columns = 3))`
</code></pre>

<p><img src="John%20Elliott%20Class%20Project%20for%20Machine%20Learning%20by%20DrJohnElliott_files/Rplot.png" alt="Feature Plot of predictors"></p>

<h1>
<a id="model-development-of-classification-trees" class="anchor" href="#model-development-of-classification-trees" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><strong>Model development of Classification Trees:</strong>
</h1>

<h2>
<a id="model-one" class="anchor" href="#model-one" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><strong>Model One:</strong>
</h2>

<p>The first model is a classification tree (method = “rpart”) using all
 predictors. The model uses the default train control method of 
resampling, cross validation “cv”, and a fold of 10.</p>

<pre><code>   ` set.seed(1972)`
`model_1         &lt;- train(as.factor(classe) ~ . ,  method = "rpart", data = trainingData)`
    `fancyRpartPlot(model_1$finalModel)`
</code></pre>

<p><img src="John%20Elliott%20Class%20Project%20for%20Machine%20Learning%20by%20DrJohnElliott_files/Mod_1.png" alt="Model 1: Classification Tree"></p>

<p>The first model was not able to discern classe type “D”, the 
alternate set of predictors were used to create the second model a 
pruned version of the first classification tree.</p>

<h2>
<a id="model-two" class="anchor" href="#model-two" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><strong>Model Two:</strong>
</h2>

<p>Model two also uses the default train control method of resampling, cross validation “cv”, and a fold of 10.</p>

<pre><code>`model_2         &lt;- train(as.factor(classe) ~ accel_belt_y + accel_belt_z + magnet_belt_x + magnet_belt_y + accel_dumbbell_z + magnet_dumbbell_x + magnet_dumbbell_y + magnet_dumbbell_z + roll_forearm + pitch_forearm + yaw_forearm + total_accel_forearm + gyros_forearm_x , method = "rpart", data = trainingData)`        
    `fancyRpartPlot(model_2$finalModel)`
</code></pre>

<p><img src="John%20Elliott%20Class%20Project%20for%20Machine%20Learning%20by%20DrJohnElliott_files/Mod_2.png" alt="Model 2: Clasification Tree with sub-setted predictors"></p>

<h2>
<a id="validation-of-the-classification-trees" class="anchor" href="#validation-of-the-classification-trees" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><strong>Validation of the Classification Trees</strong>
</h2>

<p>Validation of the two models was performed using the validation data that was sub-setted from the training data.</p>

<pre><code>`mod1_prediction &lt;- predict(model_1, validate)`
`mod2_prediction &lt;- predict(model_2, validate)`
`mod1_confusion  &lt;- as.matrix(confusionMatrix(validate$classe, mod1_prediction))`
`mod2_confusion  &lt;- as.matrix(confusionMatrix(validate$classe, mod2_prediction))`
`accuracy_mod1   &lt;- confusionMatrix(validate$classe, mod1_prediction)$overall[1]`
`accuracy_mod2   &lt;- confusionMatrix(validate$classe, mod2_prediction)$overall[1]`
`Predictions made with Classification Trees:`
`mod1_predict    &lt;- predict(model_1, testingData)`
`mod2_predict    &lt;- predict(model_2, testingData)`
</code></pre>

<p>Model 1 has better accuracy at 0.5661337 compared to model 2 accuracy
 of 0.4779554 . Since both models have an accuracy below 60% another 
model was developed.</p>

<h2>
<a id="model-development-of-random-forests" class="anchor" href="#model-development-of-random-forests" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><strong>Model development of Random Forests</strong>
</h2>

<p>The last model explored is a Random Forest (method = “rf”) using all predictor variables.</p>

<h2>
<a id="model-three" class="anchor" href="#model-three" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><strong>Model Three:</strong>
</h2>

<p>For the training The train control used was k fold cross validation “cv”, with a k fold value of 5.</p>

<pre><code>`myControl       &lt;- trainControl(method = "cv", number = 5)`
`mod3            &lt;- train(as.factor(classe) ~ .,method="rf",trControl=myControl,data=trainingData)`
</code></pre>

<h2>
<a id="validation-of-the-random-forest" class="anchor" href="#validation-of-the-random-forest" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><strong>Validation of the Random Forest</strong>
</h2>

<p>Validation of the Random Forest model was performed using the validation data that was sub-setted from the training data.</p>

<pre><code>`val_predict     &lt;- predict(mod3, validate)`
`My_Confusion    &lt;- as.matrix(confusionMatrix(validate$classe, val_predict))`
`accuracy_mod3   &lt;- confusionMatrix(validate$classe, val_predict)$overall[1]`  
</code></pre>

<p>The Random Forest model is able to predict all classe types and has an accuracy approaching 100% based on the validation data.</p>

<pre><code>`mod3_predict    &lt;- predict(mod3, testingData)`
</code></pre>

<h2>
<a id="model-comparison" class="anchor" href="#model-comparison" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><strong>Model Comparison</strong>
</h2>

<h4>
<a id="out-of-sample-error-estimation" class="anchor" href="#out-of-sample-error-estimation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Out of sample error estimation</h4>

<pre><code>`Out_S_Error_1 &lt;- 1- confusionMatrix(validate$classe, mod1_prediction)$overall[3]`
`Out_S_Error_2 &lt;- 1 - confusionMatrix(validate$classe, mod2_prediction)$overall[3]`
`Out_S_Error_3 &lt;- 1 - confusionMatrix(validate$classe, val_predict)$overall[3]`
</code></pre>

<h4>
<a id="accuracy-and-prediction" class="anchor" href="#accuracy-and-prediction" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Accuracy and Prediction</h4>

<p>Tables of the accuracy and prediction values are created for model comparison.</p>

<pre><code>`Accuracy_Table          &lt;- as.data.frame(matrix(nrow=3,ncol=2))`
`Method                  &lt;- c("Classification Tree", "Sub-setted Tree", "Random Forest")`
`rownames(Accuracy_Table)&lt;-c("Model 1", "Model 2", "Model 3")`
`colnames(Accuracy_Table)&lt;- c( "Method Used", "Accuracy")`
`Accuracy_Table[,1]      &lt;- as.data.frame(Method)`
`Accuracy_Table[1,2]     &lt;- as.data.frame(accuracy_mod1)`
`Accuracy_Table[2,2]     &lt;- as.data.frame(accuracy_mod2)`
`Accuracy_Table[3,2]     &lt;- as.data.frame(accuracy_mod3)`
`Predict_Table           &lt;- as.data.frame(matrix(nrow=3,ncol=20))`
`rownames(Predict_Table) &lt;-c("Model 1", "Model 2", "Model 3")`
`Predict_Table[1, ]       &lt;- mod1_predict`
`Predict_Table[2, ]       &lt;- mod2_predict`
`Predict_Table[3, ]       &lt;- mod3_predict`
`(Accuracy_Table)`
</code></pre>

<hr>

<pre><code>`            Method Used             Accuracy`
`Model 1     Classification Tree     0.5661337`
`Model 2     Sub-setted Tree         0.4779554`
`Model 3     Random Forest           1.0000000`
</code></pre>

<hr>

<pre><code>`(Predict_Table)`
</code></pre>

<hr>

<pre><code> `Model 1    A  A  C  A  A  C  C  C  A   A   C   C   C   A   C   C   A   A   A   C`
 `Model 2    C  A  D  A  A  C  D  A  A   A   C   D   C   A   D   A   E   A   A   D`
 `Model 3    B  A  B  A  A  E  D  B  A   A   B   C   B   A   E   E   A   B   B   B`
</code></pre>

<hr>

<h2>
<a id="plots-of-the-confusion-matrix-for-each-model" class="anchor" href="#plots-of-the-confusion-matrix-for-each-model" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Plots of the Confusion Matrix for each model</h2>

<pre><code>`library(reshape2)`
`melted_mod1_confusion   &lt;- melt(mod1_confusion)`
`melted_mod2_confusion   &lt;- melt(mod2_confusion)`
`melted_My_Confusion     &lt;- melt(My_Confusion)`
`colnames( melted_mod1_confusion ) &lt;- c("Classe", "Predicted","value")`
`colnames( melted_mod2_confusion ) &lt;- c("Classe", "Predicted","value")`
`colnames( melted_My_Confusion ) &lt;- c("Classe", "Predicted","value")`
`library(gridExtra)`
`g1 &lt;-ggplot(data = melted_mod1_confusion, aes(x=Classe, y=Predicted, fill=value)) + `
`geom_tile() + ggtitle("Model 1") + coord_fixed(ratio=1)`
`g2 &lt;-ggplot(data = melted_mod2_confusion, aes(x=Classe, y=Predicted, fill=value)) + `
`geom_tile() + ggtitle("Model 2") + coord_fixed(ratio=1)`
`g3 &lt;- ggplot(data = melted_My_Confusion, aes(x=Classe, y=Predicted, fill=value)) + `
`geom_tile() + ggtitle("Model 3") + coord_fixed(ratio=1)`
`grid.arrange(g1, g2, g3, ncol = 3)`
</code></pre>

<p><img src="John%20Elliott%20Class%20Project%20for%20Machine%20Learning%20by%20DrJohnElliott_files/confusionMatices.png" alt="Confusion Matrices of the Models"></p>

<p>The plots above of the confusion matrices, show how the Random Forest
 model performance (model 3) out performs the Classification Tree model.
 It can also be seen that Model 1 can not predict Classe type “D”.</p>

<h1>
<a id="summary-and-conclusions" class="anchor" href="#summary-and-conclusions" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><strong>Summary and Conclusions:</strong>
</h1>

<p>The random Forest model out performed the Classification Tree and 
Pruned tree models by leaps and bounds with an accuracy over 99% and an 
estimated out of sample error of  0.0008932247 with this data set it is 
the best model selection. The model was able to predict all outcomes of 
the test data accurately. </p>

<pre><code>`Predictions from Model 3: B  A  B  A  A  E  D  B  A   A   B   C   B   A   E   E   A   B   B   B`
</code></pre>

<p>An important note is that the results are only based on the data set 
that the models were trained on and it is expected the results could be 
different for data collected under different circumstances and 
conditions, such as new individuals who perform the exercises. The RMD 
file containing all the code used for this project can be found at <a href="https://github.com/DrJohnElliott/MachineLearning/blob/master/Class_Project_week_4.Rmd">Complete R-Code</a></p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/DrJohnElliott/MachineLearning">John Elliott Class Project for Machine Learning</a> is maintained by <a href="https://github.com/DrJohnElliott">DrJohnElliott</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com/">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  

</body></html>